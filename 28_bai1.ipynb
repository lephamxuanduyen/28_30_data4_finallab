{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Câu 1\n",
    "# =====\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO # For EMOTICONS\n",
    "\n",
    "def std_text(text):\n",
    "    # Mở tệp txt\n",
    "    with open(\"teencode.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        # Đọc các dòng trong tệp\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Tạo dict\n",
    "    lookup_dict = {}\n",
    "    for line in lines:\n",
    "        # Cắt dòng thành hai phần, khóa và giá trị\n",
    "        key, value = line.split(\"\\t\")\n",
    "\n",
    "        # Thêm cặp khóa-giá trị vào dict\n",
    "        lookup_dict[key.strip()] = value.strip()\n",
    "    \n",
    "    words = text.split()\n",
    "    # Get Abbreviations Words\n",
    "    text_pre=\"\"\n",
    "    for word in words:\n",
    "        w=word\n",
    "        w = re.sub(r'[^\\w\\s]','',w) #Removing Punctuation\n",
    "        if w.lower() in lookup_dict:\n",
    "            word=lookup_dict[w]\n",
    "        text_pre=text_pre + \" \" + word        \n",
    "    return text_pre\n",
    "        \n",
    "def converting_emojis(text):\n",
    "    for x in EMOTICONS_EMO:\n",
    "        text = text.replace(x, \"_\".join(EMOTICONS_EMO[x].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    for x in UNICODE_EMOJI:\n",
    "        text = text.replace(x, \"_\".join(UNICODE_EMOJI[x].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "def remove_stopword(text):\n",
    "    with open(\"vietnamese-stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        vn = f.read()\n",
    "\n",
    "    #Get Stop words Dictionaries\n",
    "    List_StopWords=vn.split(\"\\n\")\n",
    "\n",
    "    #remove stop words\n",
    "    text_pre=\" \".join(text for text in text.split() if text not in List_StopWords)\n",
    "    return text_pre\n",
    "\n",
    "# Lấy danh sách các file trong thư mục\n",
    "files = os.listdir(\"Data4\")\n",
    "# Duyệt qua các file\n",
    "for file in files:\n",
    "    # Đọc file\n",
    "    # Nối đường dẫn\n",
    "    path = os.path.join(\"Data4\", file)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    # Xử lý dữ liệu\n",
    "    text = data.lower() # viết thường\n",
    "    text =converting_emojis(text) #chuyển icon thành văn bản\n",
    "    text = text.replace(\" .\",\"\\n\") # tách câu\n",
    "    text = re.sub(r'[^\\w\\s]','',text) #xóa dấu câu\n",
    "    text = re.sub(\"\\d+\", \" \", text) #xóa số\n",
    "    text = text.split(\"\\n\")\n",
    "    file_path = os.path.join(\"Data4_solved\", file)\n",
    "    for i in range(len(text)): \n",
    "        text[i] = remove_stopword(text[i]) #loại bỏ stop word\n",
    "        text[i] = std_text(text[i]) #chuẩn hóa văn bản\n",
    "        print(text[i])\n",
    "        with open(\"data.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            # Ghi tất cả dữ liệu vào 1 file\n",
    "            f.writelines(text[i] + \"\\n\")\n",
    "        \n",
    "        with open(file_path, \"a\", encoding=\"utf-8\") as x:\n",
    "            x.write(text[i])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
